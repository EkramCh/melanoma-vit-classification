
# ğŸ§  Melanoma Classification using Vision Transformer (ViT)

<p align="center">
  <img src="ViT.jpg" alt="Vision Transformer Architecture" width="700"/>
</p>

## ğŸ“Œ Overview

This project applies **Vision Transformer (ViT)** for the **classification of melanoma skin cancer images**, leveraging **transfer learning**. The model architecture and parameters follow the official implementation described in the paper:  
ğŸ“„ [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https://arxiv.org/pdf/2010.11929)

## ğŸ“‚ Dataset

The dataset used in this project is publicly available on Kaggle:  
ğŸ”— [Melanoma Skin Cancer Dataset of 10,000 Images](https://www.kaggle.com/datasets/hasnainjaved/melanoma-skin-cancer-dataset-of-10000-images)

It includes labeled images for different skin lesion types including melanoma.

## âš™ï¸ Key Features

- âœ… Pretrained ViT model via transfer learning  
- âœ… Patch embedding and positional encoding  
- âœ… Fine-tuning MLP head for classification  
- âœ… Training with the same hyperparameters as in the original ViT paper

## ğŸš€ How to Use

1. Clone the repo:
   ```bash
   git clone https://github.com/EkramCh/melanoma-vit-classification.git
   cd melanoma-vit-classification
   ```

2. Download the dataset from Kaggle and place it in the `data/` directory.

3. train using the notebook.
4. Output
   <p align="center">
  <img src="Melanoma_Results_samples.jpg" alt="Melanoma_Results_samples" width="700"/>
</p>
